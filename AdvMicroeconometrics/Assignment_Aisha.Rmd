---
title: "Adv. Microeconometrics Computer Assignment"
author: "A. Schmidt"
date: "11/19/2020"
output:
  html_document:
    df_print: paged
bibliography: references.bib
---

  pdf_document: default


```{r, message = FALSE, warning = FALSE, echo = FALSE}
# Verify if a package is already installed, if not, download and install before loading. 
chooseCRANmirror(graphics = FALSE, ind = 10)
if (!require("pacman")) install.packages("pacman")
pacman::p_load(ggplot2, MASS, knitr, ivreg, gridExtra, RColorBrewer, latex2exp, ggExtra, grid, R.matlab)
```

```{r, message = FALSE, warning = FALSE, echo = FALSE}
# Prevents code from getting out of the page
## Works with almost everything except urls and strings.
opts_chunk$set(tidy.opts=list(width.cutoff=50),tidy=TRUE)
```

# 1 - Size distortions

Simulate data from the following model:

\begin{align*}
  Y &= X \beta + \varepsilon \\
  X &= Z\Pi + V
\end{align*}
where:
* $Y$ and $X$ are $n \times 1$ vectors which contain the endogenous variables;
* $Z$ is a $n \times k$ matrix of instruments;
* $\varepsilon$ and $V$ are $n \times 1$ vectors that contain disturbances.
* The different rows of $\left(\varepsilon\ \vdots\ V\right)$, are independently normally distributed, i.e., 

\begin{align*}
  \begin{pmatrix}
    \varepsilon_i \\
    V_i
  \end{pmatrix} \sim \mathcal{N}(0, \Sigma), \qquad 
  \Sigma =
  \begin{pmatrix}
  1 & \vdots & \rho \\
  \rho & & 1
  \end{pmatrix}
\end{align*}
* $n=100$, $k=10$, $\Pi = a \times e_{10}$ with $e_{10} \in \mathbb{R}^{10}$ whose first element is $1$ and the remaining are equal to zero.
* All elements from $Z$ are independently distributed and follows a standard normal distribution.
* $a \in \{0.3,.0.25, 0.2, 0.15, 0.1, 0.05, 0 \}$
* $\rho \in \{0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95 \}$

```{r, echo = FALSE, warning = FALSE}
  # This block is a static block that is kept through all 5000 simulations


  # Preparing data
  set.seed(6969)

  # Magic numbers

  dn    <- 100
  dk    <- 10
  va    <- matrix(c(0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0), nrow = 7, ncol = 1)
  vrho  <- c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95)
  dbeta <- 0
  dsim  <- 100
  rgrid <- seq(0,200,1)

  
  ## INITIALIZATION ##
  # Generate the Z matrix and associates
  mZ   = matrix(rep(0, dn*dk), nrow = dn, ncol = dk)
  
  for (j in 1:ncol(mZ)){
    mZ[,j] <- rnorm(nrow(mZ), mean = 0, sd = 1)
  }
  Pz <- mZ %*% solve(t(mZ) %*% mZ) %*% t(mZ)
  MZ <- diag(nrow=nrow(Pz))-Pz

  # Building a matrix with all Pi
  ve10 <- matrix(c(1, rep(0, dk-1)), nrow=10, ncol = 1)
  mPi  <- t(va %*% t(ve10))
  
  cores <- brewer.pal(7, "Dark2")

```


```{r, echo = FALSE, warning = FALSE} 
# This block simulates the model

fsimul <- function(dn, va, vrho, dBeta, mPi){
  mEV <- array(rep(0, dn*2*length(vrho)), dim = c(dn, 2, length(vrho)))
  
  # Builds the errors sampling from the multivariate normal distribution
  for (i in 1:length(vrho)){
    Sigma   <- matrix(c(1,vrho[i],vrho[i],1),2,2)
    for (j in 1:dn){
      pair    <- mvrnorm(n = 1, rep(0, 2), Sigma)
      mEV[j,,i] <- pair
    }
  }
  
  # Builds X
  lX = list(1,2,3,4,5,6,7,8,9,10)
  
  for(i in 1:length(lX)){
    lX[[i]] <- matrix(rep(0, dn*length(va)), nrow = dn, ncol = length(va))
  }
  
  
  for (j in 1:length(vrho)){
    for (i in 1:length(va)){
      lX[[j]][,i] = mZ %*% mPi[,i] + mEV[,2,j]
    }
  }
  
  # Builds Y
  lY = list(1,2,3,4,5,6,7,8,9,10)
  
  for(i in 1:length(lX)){
    lY[[i]] <- matrix(rep(0, dn*length(va)), nrow = dn, ncol = length(va))
  }
  
  for (j in 1:length(vrho)){
    for (i in 1:length(va)){
      lY[[j]][,i] = lX[[j]][,i] * dbeta + mEV[,1,j]
    }
  }
  
  return(list(lY, lX, mEV))
}
  
```


## Item 1

_For each value of $\alpha$ make a figure of the rejection frequency as a function of $\rho$ when testing $H_0: \beta = 0$ with $95\%$ significance using the $2SLS$ $t$-statistic (so five figures which show the rejection frequency as a function of $\alpha$)._

```{r, echo = FALSE, warning = FALSE, eval = TRUE}
  simul_results <- vector(mode = "list", length = dsim)
  
  for (k in 1:dsim){
    # Gets the model
    my_model <- list(1,2,3)
    my_model <- fsimul(dn, va, vrho, dBeta, mPi)
    lY       <- my_model[[1]]
    lX       <- my_model[[2]]
    mEV      <- my_model[[3]]

    mBetahat    <- matrix(rep(0, length(va)*length(vrho)), ncol = length(vrho), nrow = length(va))
    mpvaluebeta <- matrix(rep(0, length(va)*length(vrho)), ncol = length(vrho), nrow = length(va))
    mrejectbeta <- matrix(rep(0, length(va)*length(vrho)), ncol = length(vrho), nrow = length(va))
    
    for (j in 1:length(vrho)){
      for (i in 1:length(va)){
        model_2sls         <- ivreg(lY[[j]][,i] ~ lX[[j]][,i] - 1 | mZ[,1] + mZ[,2] + mZ[,3] + mZ[,4] + mZ[,5] + mZ[,6] + mZ[,7] + mZ[,8] + mZ[,9] + mZ[,10])
        mBetahat[i,j]      <- model_2sls$coefficients
        summarybeta        <- summary(model_2sls)
        mpvaluebeta[i,j]   <- summarybeta$coefficients[4]
        mrejectbeta[i,j]   <- ifelse(mpvaluebeta[i,j] < 0.05, 1, 0)
      }
    }
    simul_results[[k]] <- mrejectbeta
  }

  results_final <- 0*simul_results[[1]]

  for (i in 1:dsim){
    results_final <- results_final + simul_results[[i]]
  }

```

Graph for Q1

```{r, echo = FALSE, warning = FALSE, eval = TRUE}

   df1 <- data.frame(Rho = 0, Alpha = 0, Freq = 0) 


   for (i in 1:length(va)){
     df  <- data.frame(Rho = vrho, Alpha = va[i], Freq = results_final[i,])
     df1 <- rbind(df1, df)
   }
   df1 <- df1[-1,]
   
   df1$Freq <- round(df1$Freq/dsim*100,0)

   
   p1 <- ggplot(df1[df1$Alpha == 0.30,], aes(x = factor(Rho), y = Freq)) + 
      geom_bar(stat = 'identity', alpha = .4, colour = cores[1], fill = cores[1], width=0.6)+
      scale_x_discrete(TeX('$\\rho$'))+
      scale_y_continuous(TeX('% of times $H_0: \\beta = 0$ was rejected'), breaks = seq(0, 100, by = 10), limits = c(0,100))+
      theme(axis.title = element_text(size=9), axis.text.x = element_text(size = 7), panel.border = element_blank(), axis.line = element_line(colour = "black"))+
      labs(title = TeX('$a = 0.30$'))+
      theme_bw()+
      removeGridX()
      
   
   p2 <- ggplot(df1[df1$Alpha == 0.25,], aes(x = factor(Rho), Freq)) + 
      geom_bar(stat = 'identity', alpha = .4, colour = cores[2], fill = cores[2], width=0.6)+
      scale_x_discrete(TeX('$\\rho$'))+
      scale_y_continuous(TeX('% of times $H_0: \\beta = 0$ was rejected'), breaks = seq(0, 100, by = 10), limits = c(0,100))+
      theme(axis.title = element_text(size=9), axis.text.x = element_text(size = 7), panel.border = element_blank(), axis.line = element_line(colour = "black"))+
      labs(title = TeX('$a = 0.25$'))+
      theme_bw()+
      removeGridX()
   
   p3 <- ggplot(df1[df1$Alpha == 0.20,], aes(x = factor(Rho), Freq)) + 
      geom_bar(stat = 'identity', alpha = .4, colour = cores[3], fill = cores[3], width=0.6)+
      scale_x_discrete(TeX('$\\rho$'))+
      scale_y_continuous(TeX('% of times $H_0: \\beta = 0$ was rejected'), breaks = seq(0, 100, by = 10), limits = c(0,100))+
      theme(axis.title = element_text(size=9), axis.text.x = element_text(size = 7), panel.border = element_blank(), axis.line = element_line(colour = "black"))+
      labs(title = TeX('$a = 0.20$'))+
      theme_bw()+
      removeGridX()
   
   p4 <- ggplot(df1[df1$Alpha == 0.15,], aes(x = factor(Rho), Freq)) + 
      geom_bar(stat = 'identity', alpha = .4, colour = cores[4], fill = cores[4], width=0.6)+
      scale_x_discrete(TeX('$\\rho$'))+
      scale_y_continuous(TeX('% of times $H_0: \\beta = 0$ was rejected'), breaks = seq(0, 100, by = 10), limits = c(0,100))+
      theme(axis.title = element_text(size=9), axis.text.x = element_text(size = 9), panel.border = element_blank(), axis.line = element_line(colour = "black"))+
      labs(title = TeX('$a = 0.15$'))+
      theme_bw()+
      removeGridX()
   
   p5 <- ggplot(df1[df1$Alpha == 0.10,], aes(x = factor(Rho), Freq)) + 
      geom_bar(stat = 'identity', alpha = .4, colour = cores[5], fill = cores[5], width=0.6)+
      scale_x_discrete(TeX('$\\rho$'))+
      scale_y_continuous(TeX('% of times $H_0: \\beta = 0$ was rejected'), breaks = seq(0, 100, by = 10), limits = c(0,100))+
      theme(axis.title = element_text(size=9), axis.text.x = element_text(size = 9), panel.border = element_blank(), axis.line = element_line(colour = "black"))+
      labs(title = TeX('$a = 0.10$'))+
      theme_bw()+
      removeGridX()
   
   p6 <- ggplot(df1[df1$Alpha == 0.05,], aes(x = factor(Rho), Freq)) + 
      geom_bar(stat = 'identity', alpha = .4, colour = cores[6], fill = cores[6], width=0.6)+
      scale_x_discrete(TeX('$\\rho$'))+
      scale_y_continuous(TeX('% of times $H_0: \\beta = 0$ was rejected'), breaks = seq(0, 100, by = 10), limits = c(0,100))+
      theme(axis.title = element_text(size=9), axis.text.x = element_text(size = 9), panel.border = element_blank(), axis.line = element_line(colour = "black"))+
      labs(title = TeX('$a = 0.05$'))+
      theme_bw()+
      removeGridX()
   
   p7 <- ggplot(df1[df1$Alpha == 0.00,], aes(x = factor(Rho), Freq)) + 
      geom_bar(stat = 'identity', alpha = .4, colour = cores[7], fill = cores[7], width=0.6)+
      scale_x_discrete(TeX('$\\rho$'))+
      scale_y_continuous(TeX('% of times $H_0: \\beta = 0$ was rejected'), breaks = seq(0, 100, by = 10), limits = c(0,100))+
      theme(axis.title = element_text(size=9), axis.text.x = element_text(size = 9), panel.border = element_blank(), axis.line = element_line(colour = "black"))+
      labs(title = TeX('$a = 0.00$'))+
      theme_bw()+
      removeGridX()
   
   blank <- grid.rect(gp=gpar(col="white"))
   
    total <- ggplot(df1, aes(x = Rho, y = Freq, color = factor(Alpha))) + 
      geom_line()+
      scale_x_continuous(TeX('$\\rho$'), breaks = seq(0, 1, by = 0.1))+
      scale_y_continuous(TeX('% of times $H_0: \\beta = 0$ was rejected'), breaks = seq(0, 100, by = 10), limits = c(0,100))+
      theme(axis.title = element_text(size=9), axis.text.x = element_text(size = 7), panel.border = element_blank(), axis.line = element_line(colour = "black"))+
      theme_bw()+
      labs(color = TeX("$a$"))+
      removeGridX()
    total <- total+theme(legend.position = c(0.15, 0.55))
    total <- total + theme(legend.background = element_rect(fill="transparent"), legend.text = element_text(size = 6), legend.title = element_text(size=6))

#pdf(file = "C:\\Users\\aisha\\OneDrive\\Documentos\\Mestrado Tinbergen\\Year 2\\Block 02\\Advanced Microeconometrics\\Computer assignment\\Mphil\\AdvMicroeconometrics\\Q1\\Fig01-Q1.pdf", width = 6, height = 3)
  grid.arrange(p1, p2, ncol=2, nrow=1)
#dev.off()

  
  #pdf(file = "C:\\Users\\aisha\\OneDrive\\Documentos\\Mestrado Tinbergen\\Year 2\\Block 02\\Advanced Microeconometrics\\Computer assignment\\Mphil\\AdvMicroeconometrics\\Q1\\Fig09-Q1.pdf", width = 6, height = 3)
  grid.arrange(p1, p7, ncol=2, nrow=1)
#dev.off()



#pdf(file = "C:\\Users\\aisha\\OneDrive\\Documentos\\Mestrado Tinbergen\\Year 2\\Block 02\\Advanced Microeconometrics\\Computer assignment\\Mphil\\AdvMicroeconometrics\\Q1\\Fig02-Q1.pdf", width = 6, height = 3)
  grid.arrange(p3, p4, ncol=2, nrow=1)
#dev.off()



#pdf(file = "C:\\Users\\aisha\\OneDrive\\Documentos\\Mestrado Tinbergen\\Year 2\\Block 02\\Advanced Microeconometrics\\Computer assignment\\Mphil\\AdvMicroeconometrics\\Q1\\Fig03-Q1.pdf", width = 6, height = 3)
  grid.arrange(p5, p6, ncol=2, nrow=1)
#dev.off()



#pdf(file = "C:\\Users\\aisha\\OneDrive\\Documentos\\Mestrado Tinbergen\\Year 2\\Block 02\\Advanced Microeconometrics\\Computer assignment\\Mphil\\AdvMicroeconometrics\\Q1\\Fig04-Q1.pdf", width = 6, height = 3)
  grid.arrange(p7, blank, ncol=2, nrow=1)
#dev.off()


#pdf(file = "C:\\Users\\aisha\\OneDrive\\Documentos\\Mestrado Tinbergen\\Year 2\\Block 02\\Advanced Microeconometrics\\Computer assignment\\Mphil\\AdvMicroeconometrics\\Q1\\Fig05-Q1.pdf", width = 6, height = 3)
  grid.arrange(p7, total, ncol=2, nrow=1)
#dev.off()

  


#pdf(file = "C:\\Users\\aisha\\OneDrive\\Documentos\\Mestrado Tinbergen\\Year 2\\Block 02\\Advanced Microeconometrics\\Computer assignment\\Mphil\\AdvMicroeconometrics\\Q1\\Fig06-Q1.pdf", width = 6, height = 3)
  total
#dev.off()
  

```

## Question 2

_Compute and make a figure of the 95% critical value function of the LR statistic as a function of $r(\beta_0)$ for $k=10$. What can you say about the critical value when $r(\beta_0)=0$ or infinite?_

```{r, echo = FALSE, warning = FALSE, eval = TRUE} 
  
  PsiOne       <- rchisq(dsim, df=1)
  PsiKminusOne <- rchisq(dsim, df=dk-1)
  
  vLR <- matrix(rep(0), dsim*length(rgrid), nrow = dsim, ncol = length(rgrid))
  

  for (g in 1:length(rgrid)){
    for (s in 1:dsim){
      vLR[s,g] <- 0.5*(PsiKminusOne[s] + PsiOne[s] - rgrid[g] +sqrt((PsiKminusOne[s] + PsiOne[s] + rgrid[g])^2-4*rgrid[g]*PsiKminusOne[s]))
    }
  }

  LRcv <- apply(vLR, 2, quantile, probs=c(0.95), na.rm=TRUE)
  df1 <- data.frame(RBeta = rgrid, LRcv)
  
  p1 <- ggplot(df1, aes(x = RBeta, y = LRcv))+
    geom_line(colour = cores[1], size = 0.5)+
    scale_x_continuous(TeX('$r(\\beta_0)$'), limits = c(0, 200))+
    scale_y_continuous(TeX('95% critical value of the LR statistic'), limits = c(0,17), breaks = seq(1,18,1))+
    theme(axis.title = element_text(size=9), axis.text.x = element_text(size = 9), panel.border = element_blank(), axis.line = element_line(colour = "black"))+
    theme_bw()+
    removeGridX()
  
#pdf(file = "C:\\Users\\aisha\\OneDrive\\Documentos\\Mestrado Tinbergen\\Year 2\\Block 02\\Advanced Microeconometrics\\Computer assignment\\Mphil\\AdvMicroeconometrics\\Q1\\Fig07-Q1.pdf", width = 6, height = 3)
  p1
#dev.off()
```

## Question 3

Repeat exercise 1 for the AR, score and LR statistics. What you conclude?

```{r, echo = FALSE, warning = FALSE, eval = TRUE} 
 
  simul_resultsAR <- vector(mode = "list", length = dsim)
  crit_AR <- qchisq(0.95,dk)/dk
  mrejectbetaAR <- matrix(rep(0, length(va)*length(vrho)), ncol = length(vrho), nrow = length(va))
  
  
  simul_resultsLM <- vector(mode = "list", length = dsim)
  crit_LM <- qchisq(0.95,1)
  mrejectbetaLM <- matrix(rep(0, length(va)*length(vrho)), ncol = length(vrho), nrow = length(va))
  
  simul_resultsLR <- vector(mode = "list", length = dsim)
  mrejectbetaLR <- matrix(rep(0, length(va)*length(vrho)), ncol = length(vrho), nrow = length(va))
  
  for (k in 1:dsim){
  ### Gets the model
   my_model <- list(1,2,3)
   my_model <- fsimul(dn, va, vrho, dBeta, mPi)
   lY       <- my_model[[1]]
   lX       <- my_model[[2]]
   mEV      <- my_model[[3]]
    
    # For each combination of rho and a, compute the test statistic
    for (j in 1:length(vrho)){
      for (i in 1:length(va)){
        
        dEps               <- lY[[j]][,i] - lX[[j]][,i]*dbeta
        dSigEps            <- (1/(dn-dk))*(t(dEps) %*% MZ %*% (dEps))
        dSigVEps           <- (1/(dn-dk))*(t(dEps) %*% MZ %*% lX[[j]][,i])
        dhatrho            <- dSigVEps/dSigEps
        mTildePi           <- solve(t(mZ) %*% mZ) %*% t(mZ) %*% (lX[[j]][,i] -  dEps * dhatrho)
        ZTildePi           <- mZ %*% mTildePi
        mPZTildePi         <- (ZTildePi) %*% solve(t(ZTildePi) %*% ZTildePi) %*% t(ZTildePi)
        
        # AR
        model_AR_num       <- ((t(dEps) %*% Pz %*% (dEps))/dk)/((t(dEps) %*% MZ %*% (dEps))/(dn-dk))
        mrejectbetaAR[i,j] <- ifelse(model_AR_num > crit_AR, 1, 0)
        
        # LM
        model_LM_num       <- (1/dSigEps)*(t(dEps) %*% mPZTildePi %*% dEps)
        mrejectbetaLM[i,j] <- ifelse(model_LM_num > crit_LM, 1, 0)
        
        # LR
        mSigmaVV   <- (1/(dn-dk))*(t(lX[[j]][,i]) %*% MZ %*% lX[[j]][,i])
        mSigmaVEps <- mSigmaVV - (dSigVEps^2)/dSigEps
        dkAR       <- (1/dSigEps)*(t(dEps) %*% Pz %*% dEps)
        drbeta     <- (1/mSigmaVEps)* (t(mTildePi) %*% t(mZ) %*% mZ %*% mTildePi)
        dLMB0      <- model_LM_num
        
        model_LR_num       <- 0.5*(dkAR - drbeta + sqrt((dkAR + drbeta)^2 - 4*drbeta*(dkAR-dLMB0)))
        cr_pos             <- match(min(abs(rgrid - drbeta)), abs(rgrid - drbeta))
        crit_LR            <- LRcv[cr_pos]
        mrejectbetaLR[i,j] <- ifelse(model_LR_num > crit_LR, 1, 0)
        
      }
    }
    simul_resultsAR[[k]] <- mrejectbetaAR
    simul_resultsLM[[k]] <- mrejectbetaLM
    simul_resultsLR[[k]] <- mrejectbetaLR
  }
  

  ARresults_final <- 0*simul_resultsAR[[1]]

  for (i in 1:dsim){
    ARresults_final <- ARresults_final + simul_resultsAR[[i]]
  }
  
  
  LMresults_final <- 0*simul_resultsLM[[1]]

  for (i in 1:dsim){
    LMresults_final <- LMresults_final + simul_resultsLM[[i]]
  }
  
  LRresults_final <- 0*simul_resultsLR[[1]]

  for (i in 1:dsim){
    LRresults_final <- LRresults_final + simul_resultsLR[[i]]
  }
  
  # Graphs
  
   df1 <- data.frame(Rho = 0, Alpha = 0, Freq = 0)
   df2 <- data.frame(Rho = 0, Alpha = 0, Freq = 0)
   df3 <- data.frame(Rho = 0, Alpha = 0, Freq = 0)


   for (i in 1:length(va)){
     df  <- data.frame(Rho = vrho, Alpha = va[i], Freq = ARresults_final[i,])
     df1 <- rbind(df1, df)
     df  <- data.frame(Rho = vrho, Alpha = va[i], Freq = LRresults_final[i,])
     df2 <- rbind(df2, df)
     df  <- data.frame(Rho = vrho, Alpha = va[i], Freq = LMresults_final[i,])
     df3 <- rbind(df3, df)
   }
   df1 <- df1[-1,]
   df2 <- df2[-1,]
   df3 <- df3[-1,]
   
   cores <- brewer.pal(7, "Dark2")
   df1$Freq <- round(df1$Freq/dsim*100,0)
   df2$Freq <- round(df2$Freq/dsim*100,0)
   df3$Freq <- round(df3$Freq/dsim*100,0)
   
   
    total_AR <- ggplot(df1, aes(x = Rho, y = Freq, color = factor(Alpha))) + 
      geom_line()+
      scale_x_continuous(TeX('$\\rho$'), breaks = seq(0, 1, by = 0.1))+
      scale_y_continuous(TeX('% of times $H_0: \\beta = 0$ was rejected'), breaks = seq(0, 50, by = 5), limits = c(0,50))+
      theme(axis.title = element_text(size=6), axis.text.x = element_text(size = 5), panel.border = element_blank(), axis.line = element_line(colour = "black"))+
      theme_bw()+
      labs(title = TeX('AR'))+
      labs(color = TeX("$a$"))+
      removeGridX()
    total_AR <- total_AR+theme(legend.position = c(0.35, 0.65))
    total_AR <- total_AR + theme(legend.background = element_rect(fill="transparent"), legend.text = element_text(size = 5), legend.title = element_text(size=5), axis.title = element_text(size=6), axis.text.x = element_text(size = 5), axis.text.y = element_text(size = 5), panel.border = element_blank(), axis.line = element_line(colour = "black"), plot.title = element_text(size = 6), legend.direction="horizontal") 
    
    
    total_LR <- ggplot(df2, aes(x = Rho, y = Freq, color = factor(Alpha))) + 
      geom_line()+
      scale_x_continuous(TeX('$\\rho$'), breaks = seq(0, 1, by = 0.1))+
      scale_y_continuous(TeX('% of times $H_0: \\beta = 0$ was rejected'), breaks = seq(0, 50, by = 5), limits = c(0,50))+
      theme(axis.title = element_text(size=6), axis.text.x = element_text(size = 5), panel.border = element_blank(), axis.line = element_line(colour = "black"))+
      theme_bw()+
      labs(color = TeX("$a$"))+
      labs(title = TeX('LR'))+
      removeGridX()
    total_LR <- total_LR+theme(legend.position = c(0.35, 0.65))
    total_LR <- total_LR + theme(legend.background = element_rect(fill="transparent"), legend.text = element_text(size = 5), legend.title = element_text(size=5), axis.title = element_text(size=6), axis.text.x = element_text(size = 5), axis.text.y = element_text(size = 5), panel.border = element_blank(), axis.line = element_line(colour = "black"), plot.title = element_text(size = 6), legend.direction="horizontal") 

    
    total_LM <- ggplot(df3, aes(x = Rho, y = Freq, color = factor(Alpha))) + 
      geom_line()+
      scale_x_continuous(TeX('$\\rho$'), breaks = seq(0, 1, by = 0.1))+
      scale_y_continuous(TeX('% of times $H_0: \\beta = 0$ was rejected'), breaks = seq(0, 50, by = 5), limits = c(0,50))+
      theme(axis.title = element_text(size=6), axis.text.x = element_text(size = 5), axis.text.y = element_text(size = 5), panel.border = element_blank(), axis.line = element_line(colour = "black"))+
      theme_bw()+
      labs(color = TeX("$a$"))+
      labs(title = TeX('LM'))+
      removeGridX()
    total_LM <- total_LM+theme(legend.position = c(0.35, 0.65))
    total_LM <- total_LM + theme(legend.background = element_rect(fill="transparent"), legend.text = element_text(size = 5), legend.title = element_text(size=5), axis.title = element_text(size=6), axis.text.x = element_text(size = 5), axis.text.y = element_text(size = 5), panel.border = element_blank(), axis.line = element_line(colour = "black"), plot.title = element_text(size = 6), legend.direction="horizontal") 

#pdf(file = "C:\\Users\\aisha\\OneDrive\\Documentos\\Mestrado Tinbergen\\Year 2\\Block 02\\Advanced Microeconometrics\\Computer assignment\\Mphil\\AdvMicroeconometrics\\Q1\\Fig08-Q1.pdf", width = 9, height = 3)
  grid.arrange(total_AR, total_LR, total_LM, ncol=3, nrow=1) 
#dev.off() 

``` 


## Question 4

_Compute and make a figure of the 95% critical value function of the LR statistic as a function of $r(\beta_0)$ for $k=4$._

```{r, echo = FALSE, warning = FALSE, eval = TRUE}
  dk = 4
  PsiOne       <- rchisq(dsim, df=1)
  PsiKminusOne <- rchisq(dsim, df=dk-1)
  
  vLR <- matrix(rep(0), dsim*length(rgrid), nrow = dsim, ncol = length(rgrid))
  

  for (g in 1:length(rgrid)){
    for (s in 1:dsim){
      vLR[s,g] <- 0.5*(PsiKminusOne[s] + PsiOne[s] - rgrid[g] +sqrt((PsiKminusOne[s] + PsiOne[s] + rgrid[g])^2-4*rgrid[g]*PsiKminusOne[s]))
    }
  }

  LRcv2 <- apply(vLR, 2, quantile, probs=c(0.95), na.rm=TRUE)
  df1 <- data.frame(RBeta = rgrid, LRcv2)
  
  p1 <- ggplot(df1, aes(x = RBeta, y = LRcv2))+
    geom_line(colour = cores[1], size = 0.5)+
    scale_x_continuous(TeX('$r(\\beta_0)$'), limits = c(0, 200))+
    scale_y_continuous(TeX('95% critical value of the LR statistic'), limits = c(0,17), breaks = seq(1,18,1))+
    theme(axis.title = element_text(size=9), axis.text.x = element_text(size = 9), panel.border = element_blank(), axis.line = element_line(colour = "black"))+
    theme_bw()+
    removeGridX()
  
#pdf(file = "C:\\Users\\aisha\\OneDrive\\Documentos\\Mestrado Tinbergen\\Year 2\\Block 02\\Advanced Microeconometrics\\Computer assignment\\Mphil\\AdvMicroeconometrics\\Q1\\Fig010-Q1.pdf", width = 6, height = 3)
  p1
#dev.off()
  

```

## Question 5

5. Card $(1993)^{1}$ analyzes the return on education. He uses different proximity to college variables as instruments. The file assigmentweakinstruments.mat contains that part of the Card data which we use for this assignment. The different variables in the file are:

  * `nearc2`: if near a 2 year college, 
  * `nearc4`: if near a 4 year college, 
  * `nearc4a`: if near a 4 year community college, 
  * `nearc4b`: if near a 4 year private college, 
  * `ed`: years of education, 
  * `wage`: log-earnings, 
  * `age`: age in years, 
  * `age2`: squared age, 
  * `exper`: experience, 
  * `exper2`:experience squared, 
  * `south`: lives in the South, 
  * `smsa`: lives in a metropolitan area, 
  * `race`: racial indicator.

The variables `wage` and `ed` constitute the endogenous variables $(y$ and $x),$ `nearc 2`, `nearc4`, `nearc4a`, `nearc4b` are instruments ( $z$ ) and `exper`, `exper2`, `south`, `smsa`, `race` and the constant term are the included exogenous variables $(w)$ (We do not use `age` and `age2`).

**Obs**: There is something strange with the variable `nearc4b` because it is not binary.

```{r, echo = FALSE, warning = FALSE, eval = TRUE}
# Loading data
urlRemote  <- "https://github.com/aishameriane/Mphil/blob/master/"
pathGithub <- "/AdvMicroeconometrics/Q2/assignmentweakinstruments.mat?raw=true"

url      <- paste0(urlRemote, pathGithub)
df       <- readMat(url)

# In case Github doesn't work
#df <- readMat('C:\\Users\\aisha\\OneDrive\\Documentos\\Mestrado Tinbergen\\Year 2\\Block 02\\Advanced Microeconometrics\\Computer assignment\\Mphil\\AdvMicroeconometrics\\Q2\\assignmentweakinstruments.mat')


dfData01           <- data.frame(df$wage, df$ed, df$nearc2, df$nearc4, df$nearc4a, df$nearc4b, df$exper, df$exper2, df$south, df$smsa, df$race)
dfData01$intercept <- rep(1, nrow(dfData01))
names(dfData01)    <- c("wage", "ed", "nearc2", "nearc4", "nearc4a", "nearc4b", "exper", "exper2", "south", "smsa", "race", "intercept")


```


```{r, echo = FALSE, warning = FALSE, eval = TRUE}
   # Assembling the matrices
  dfY           <- matrix(dfData01$wage, ncol = 1)
  colnames(dfY) <- "wage"
  
  dfX           <- matrix(dfData01$ed, ncol = 1)
  colnames(dfX) <- c("ed")

  dfW           <- matrix(cbind(dfData01$intercept, dfData01$exper, dfData01$exper2, dfData01$south, dfData01$smsa, dfData01$race), ncol = 6)
  colnames(dfW) <- c("intercept", "exper", "exper2", "south", "smsa", "race")

  dfZ           <- matrix(cbind(dfData01$nearc2, dfData01$nearc4, dfData01$nearc4a, dfData01$nearc4b), ncol = 4)
  colnames(dfZ) <- c("nearc2", "nearc4", "nearc4a", "nearc4b")
```

### Item a
_Using only nearc2 as an instrument, construct the $95\%$ confidence set for the return on education using the $2\mathrm{SLS}$ $t$-statistic and the AR statistic._

```{r, echo = FALSE, warning = FALSE, eval = TRUE}
  mY <- dfY
  mX <- dfX
  mW <- dfW
  mZ <- matrix(dfZ[,1], ncol=1)
  dn <- nrow(dfY)
  dk <- 1
  
  # Auxiliary variables
  mPw <- mW %*% solve(t(mW) %*% mW) %*% t(mW)
  mMw <- diag(nrow=nrow(mPw))-mPw
  
    # Transform the variables as suggested in slide 49
  mY <- mMw %*% mY
  mX <- mMw %*% mX
  mZ <- mMw %*% mZ
  
  
  mPz <- mZ %*% solve(t(mZ) %*% mZ) %*% t(mZ)
  mMz <- diag(nrow=nrow(mPz))-mPz
  
  # Critical values for hypothesis testing
  crit_2SLS <- qt(0.975, dn-dk)
  crit_AR   <- qchisq(0.95,dk)/dk
  crit_LM   <- qchisq(0.95,1)
```

First, estimate all things using 2SLS.

```{r, echo = FALSE, warning = FALSE, eval = TRUE}
  # To estimate with 2SLS we need the two stages - this time not using package
  ## First stage: Pihat = (Z'Z)^{-1} Z'X
  mHPi       <- solve(t(mZ) %*% mZ) %*% t(mZ) %*% mX
  dSigmaHatV <- (1/(dn-dk)) * t(mX-mZ %*% mHPi) %*% (mX-mZ %*% mHPi)
  
  # Second stage - get Beta (can either use Pihat or just project Z)
  BetaHat    <- solve(t(mX) %*% mPz %*% mX) %*% t(mX) %*% mPz %*% mY
  
  # Computes the correct standard errors for 2sls
  dSdhat     <- sqrt(1/(dn-dk))*t(mY-mX %*% BetaHat) %*% (mY-mX %*% BetaHat) %*% solve(t(mX) %*% mPz %*% mX)
  
  # F-statistic in the first stage
  dF1st <- ((t(mHPi) %*% t(mZ) %*% mZ %*% mHPi)/dk)/dSigmaHatV
```

To build the confidence set for $\beta$ we can use the recipe from slide 52. 


```{r, echo = FALSE, warning = FALSE, eval = TRUE}
  # Make a grid for the Betas
  Betagrid <- seq(-100*BetaHat, 100*BetaHat, 0.5)

  v_cvAR   <- matrix(rep(0, length(Betagrid)))
  v_cv2sls <- matrix(rep(0, length(Betagrid)))
  
  # For each value in the grid, we compute the AR statistic and the t-statistic
  # AR: use formula from slide 52
  # t 2sls: use the regular formula
  for (i in 1:length(Betagrid)){
    res         <- mY - mX %*% Betagrid[i]
    v_cvAR[i]   <- ((t(res) %*% mPz %*% res)/dk)/((t(res) %*% mMz %*% res)/(dn-dk))
    v_cv2sls[i] <- (BetaHat - Betagrid[i])/dSdhat
  }
  
  # To build the confidence sets we evaluate which values from the beta grid exceeds the critical value
  cs_AR      <- Betagrid[v_cvAR > crit_AR]
  cs_2sls_LB <- BetaHat - 1.96*dSdhat
  cs_2sls_UB <- BetaHat + 1.96*dSdhat
```


Now we can build some graphs.

```{r, echo = FALSE, warning = FALSE, eval = TRUE}
  df2 <- data.frame(Betagrid, v_cvAR, rep(crit_AR, length(v_cvAR)), v_cv2sls, rep(cs_2sls_LB, length(v_cvAR)), rep(cs_2sls_UB, length(v_cvAR)), rep(crit_2SLS, length(v_cvAR)))
  names(df2) <- c("Betagrid", "cs_AR", "crit_AR", "t2sls", "cs_2sls_LB", "cs_2sls_UB", "crit_2SLS")
  
  
  plot_AR <- ggplot(df2, aes(x = Betagrid, y=cs_AR))+
    geom_line(color = cores[2])+
    geom_line(aes(y=crit_AR),size=1, color = cores[1], linetype = "dashed") +
      scale_x_continuous(TeX('$\\beta$'), breaks = seq(-50, 50, 5))+
      scale_y_continuous(TeX('AR statistic'), breaks = seq(0, 9, 0.5))+
      theme(axis.title = element_text(size=6), axis.text.x = element_text(size = 5), axis.text.y = element_text(size = 5), panel.border = element_blank(), axis.line = element_line(colour = "black"))+
      theme_bw()+
      removeGridX() 
  plot_AR <- plot_AR + theme(axis.title = element_text(size=7), axis.text.x = element_text(size = 6), axis.text.y = element_text(size = 6), axis.line = element_line(colour = "black")) 
  
  
  plot_t <- ggplot(df2, aes(x = Betagrid, y=t2sls))+
    geom_line(color = cores[2])+
    geom_line(aes(y=cs_2sls_LB),size=1, color = cores[1], linetype = "dashed") +
    geom_line(aes(y=cs_2sls_UB),size=1, color = cores[1], linetype = "dashed") +
      scale_x_continuous(TeX('$\\beta$'), breaks = seq(-50, 50, 5))+
      scale_y_continuous(TeX('t statistic'), breaks = seq(-20, 20, 2))+
      theme(axis.title = element_text(size=6), axis.text.x = element_text(size = 5), axis.text.y = element_text(size = 5), panel.border = element_blank(), axis.line = element_line(colour = "black"))+
      theme_bw()+
      removeGridX() 
  plot_t <- plot_t + theme(axis.title = element_text(size=7), axis.text.x = element_text(size = 6), axis.text.y = element_text(size = 6), axis.line = element_line(colour = "black"))

pdf(file = "C:\\Users\\aisha\\OneDrive\\Documentos\\Mestrado Tinbergen\\Year 2\\Block 02\\Advanced Microeconometrics\\Computer assignment\\Mphil\\AdvMicroeconometrics\\Q2\\Fig01-Q2.pdf", width = 6, height = 3)
  grid.arrange(plot_AR, plot_t, ncol=2, nrow=1)
dev.off() 

```

The value of the F-statistic is `r dF1st`. The confidence interval using the t-statistic is given by [`r cs_2sls_LB`, `r cs_2sls_UB`]. For the AR statistic, we have that the interval is going to be unbounded and disjoint: $(-\infty$ `r min(cs_AR)`$]\cup[$ `r max(cs_AR)` $,\infty)$. 

### Item b
_Is there a difference between these confidence sets and if so can you explain why this difference occurs?_

### Item c
_What is the value of the first stage F-statistic and what does the value of the AR statistic look like when the tested parameter is large._

### Item d
_We did not use the $\mathrm{LM}$ and $\mathrm{LR}$ statistics in a or did we?_

### Item e
_Using nearc4, nearc2, nearc4a and nearc4b as instruments, construct the $95 \%$ confidence set for the return on education using the $2 \mathrm{SLS} t$ -statistic, AR, LM and LR statistics._

Rebuild everything.

```{r, echo = FALSE, warning = FALSE, eval = TRUE}
  mY <- dfY
  mX <- dfX
  mW <- dfW
  mZ <- dfZ
  dn <- nrow(dfY)
  dk <- 4
  
  # Auxiliary variables
  mPw <- mW %*% solve(t(mW) %*% mW) %*% t(mW)
  mMw <- diag(nrow=nrow(mPw))-mPw
  
    # Transform the variables as suggested in slide 49
  mY <- mMw %*% mY
  mX <- mMw %*% mX
  mZ <- mMw %*% mZ
  
  
  mPz <- mZ %*% solve(t(mZ) %*% mZ) %*% t(mZ)
  mMz <- diag(nrow=nrow(mPz))-mPz
  
  # Critical values for hypothesis testing
  crit_2SLS <- qt(0.975, dn-dk)
  crit_AR   <- qchisq(0.95,dk)/dk
  crit_LM   <- qchisq(0.95,1)
```

Estimate things.

```{r, echo = FALSE, warning = FALSE, eval = TRUE}
  # Second stage - get Beta (can either use Pihat or just project Z)
  BetaHat    <- solve(t(mX) %*% mPz %*% mX) %*% t(mX) %*% mPz %*% mY
  # Computes the correct standard errors for 2sls
  dSdhat     <- sqrt(1/(dn-dk))*t(mY-mX %*% BetaHat) %*% (mY-mX %*% BetaHat) %*% solve(t(mX) %*% mPz %*% mX)
  
  Eps          <- mY - mX %*% BetaHat
  SigEps       <- (1/(dn-dk))*(t(Eps) %*% mMz %*% (Eps))
  SigVEps      <- (1/(dn-dk))*(t(Eps) %*% mMz %*% mX)
  SigVV        <- (1/(dn-dk))*(t(mX) %*% mMz %*% mX)
  hatrho       <- SigVEps/SigEps
  mTildePi     <- solve(t(mZ) %*% mZ) %*% t(mZ) %*% (mX -  Eps %*% hatrho)
  ZTildePi     <- mZ %*% mTildePi
  mPZTildePi   <- (ZTildePi) %*% solve(t(ZTildePi) %*% ZTildePi) %*% t(ZTildePi)
  r_beta_hat   <- (1/SigVV) * (t(mTildePi) %*% (t(mZ) %*% mZ) %*% mTildePi)
  
  
  Betagrid <- seq(-100*BetaHat, 100*BetaHat, 0.25)

  v_cvAR   <- matrix(rep(0, length(Betagrid)))
  v_cv2sls <- matrix(rep(0, length(Betagrid)))
  v_cvLR   <- matrix(rep(0, length(Betagrid)))
  v_cvLM   <- matrix(rep(0, length(Betagrid)))
  lr_grid  <- matrix(rep(0, length(Betagrid)))
  
  PsiOne       <- rchisq(dsim, df=1)
  PsiKminusOne <- rchisq(dsim, df=dk-1)
```

Build the confidence sets.

```{r, echo = FALSE, warning = FALSE, eval = TRUE}
  for (i in 1:length(Betagrid)){
    res         <- mY - mX %*% Betagrid[i]
    
    
    aux_Eps          <- mY - mX %*% Betagrid[i]
    aux_SigEps       <- (1/(dn-dk))*(t(aux_Eps) %*% mMz %*% (aux_Eps))
    aux_SigVEps      <- (1/(dn-dk))*(t(aux_Eps) %*% mMz %*% mX)
    aux_SigVV        <- (1/(dn-dk))*(t(mX) %*% mMz %*% mX)
    aux_hatrho       <- aux_SigVEps/aux_SigEps
    aux_mTildePi     <- solve(t(mZ) %*% mZ) %*% t(mZ) %*% (mX -  aux_Eps %*% aux_hatrho)
    aux_ZTildePi     <- mZ %*% aux_mTildePi
    aux_mPZTildePi   <- (aux_ZTildePi) %*% solve(t(ZTildePi) %*% ZTildePi) %*% t(aux_ZTildePi)
    aux_r_beta_hat   <- (1/aux_SigVV) * (t(aux_mTildePi) %*% (t(mZ) %*% mZ) %*% aux_mTildePi)
    aux_mSigmaVV     <- (1/(dn-dk))*(t(mX) %*% mMz %*% mX)
    aux_mSigmaVEps   <- aux_mSigmaVV - (aux_SigVEps^2)/aux_SigEps
    aux_dkAR         <- (1/aux_SigEps)*(t(aux_Eps) %*% mPz %*% aux_Eps)
    aux_drbeta       <- (1/aux_SigVEps)* (t(aux_mTildePi) %*% t(mZ) %*% mZ %*% aux_mTildePi)
    
    
    v_cvAR[i]      <- ((t(res) %*% mPz %*% res)/dk)/((t(res) %*% mMz %*% res)/(dn-dk))
    v_cv2sls[i]    <- (BetaHat - Betagrid[i])/dSdhat
    v_cvLM[i]      <- (1/aux_SigEps)*(t(aux_Eps) %*% aux_mPZTildePi %*% aux_Eps)
    v_cvLR[i]      <- 0.5*(aux_dkAR - aux_drbeta + sqrt((aux_dkAR + aux_drbeta)^2 - 4*aux_drbeta*(aux_dkAR-v_cvLM[i])))
    
    # Critical values for the LR test
    value      <- 0.5*(PsiKminusOne + PsiOne - aux_r_beta_hat + sqrt((PsiKminusOne + PsiOne + aux_r_beta_hat)^2 - 4*aux_r_beta_hat*PsiKminusOne))
    lr_grid[i] <- quantile(value, probs = 0.95)
  }
```

Now we make the confidence sets!

```{r, echo = FALSE, warning = FALSE, eval = TRUE}
  # To build the confidence sets we evaluate which values from the beta grid exceeds the critical value
  cs_AR      <- Betagrid[v_cvAR > crit_AR]
  cs_LM      <- Betagrid[v_cvLM > crit_AR]
  cs_LR      <- Betagrid[v_cvLR > lr_grid]
  

  cs_2sls_LB <- BetaHat - 1.96*dSdhat
  cs_2sls_UB <- BetaHat + 1.96*dSdhat
```

And finally we plot the fucking graphs:

```{r, echo = FALSE, warning = FALSE, eval = TRUE}
  df2 <- data.frame(Betagrid, v_cvAR, rep(crit_AR, length(v_cvAR)), v_cv2sls/100, rep(cs_2sls_LB, length(v_cvAR)), rep(cs_2sls_UB, length(v_cvAR)), rep(crit_2SLS, length(v_cvAR)), v_cvLM, rep(crit_LM, length(v_cvAR)), v_cvLR, lr_grid)
  names(df2) <- c("Betagrid", "cs_AR", "crit_AR", "t2sls", "cs_2sls_LB", "cs_2sls_UB", "crit_2SLS", "cs_LM", "crit_LM", "cs_LR", "crit_LR")
  
  
  plot_AR <- ggplot(df2, aes(x = Betagrid, y=cs_AR))+
    geom_line(color = cores[2])+
    geom_line(aes(y=crit_AR),size=1, color = cores[1], linetype = "dashed") +
      scale_x_continuous(TeX('$\\beta$'), breaks = seq(-50, 50, 5))+
      scale_y_continuous(TeX('AR statistic'), breaks = seq(0, 12, 2))+
      theme(axis.title = element_text(size=6), axis.text.x = element_text(size = 5), axis.text.y = element_text(size = 5), panel.border = element_blank(), axis.line = element_line(colour = "black"))+
      theme_bw()+
      removeGridX() 
  plot_AR <- plot_AR + theme(axis.title = element_text(size=7), axis.text.x = element_text(size = 6), axis.text.y = element_text(size = 6), axis.line = element_line(colour = "black")) 
  
  
  plot_t <- ggplot(df2, aes(x = Betagrid, y=t2sls))+
    geom_line(color = cores[2])+
    geom_line(aes(y=cs_2sls_LB),size=1, color = cores[1], linetype = "dashed") +
    geom_line(aes(y=cs_2sls_UB),size=1, color = cores[1], linetype = "dashed") +
      scale_x_continuous(TeX('$\\beta$'), breaks = seq(-50, 50, 5))+
      scale_y_continuous(TeX('t statistic'), breaks = seq(-2, 2, 0.5))+
      theme(axis.title = element_text(size=6), axis.text.x = element_text(size = 5), axis.text.y = element_text(size = 5), panel.border = element_blank(), axis.line = element_line(colour = "black"))+
      theme_bw()+
      removeGridX() 
  plot_t <- plot_t + theme(axis.title = element_text(size=7), axis.text.x = element_text(size = 6), axis.text.y = element_text(size = 6), axis.line = element_line(colour = "black"))
  
    plot_LM <- ggplot(df2, aes(x = Betagrid, y=cs_LM))+
    geom_line(color = cores[2])+
    geom_line(aes(y=crit_LM),size=1, color = cores[1], linetype = "dashed") +
      scale_x_continuous(TeX('$\\beta$'), breaks = seq(-50, 50, 5))+
      scale_y_continuous(TeX('LM statistic'), breaks = seq(0, 8, 1))+
      theme(axis.title = element_text(size=6), axis.text.x = element_text(size = 5), axis.text.y = element_text(size = 5), panel.border = element_blank(), axis.line = element_line(colour = "black"))+
      theme_bw()+
      removeGridX() 
  plot_LM <- plot_LM + theme(axis.title = element_text(size=7), axis.text.x = element_text(size = 6), axis.text.y = element_text(size = 6), axis.line = element_line(colour = "black"))
  
    plot_LR <- ggplot(df2, aes(x = Betagrid, y=cs_LR))+
    geom_line(color = cores[2])+
    geom_line(aes(y=crit_LR),size=1, color = cores[1], linetype = "dashed") +
      scale_x_continuous(TeX('$\\beta$'), breaks = seq(-50, 50, 5))+
      scale_y_continuous(TeX('LR statistic'), breaks = seq(0, 200, 50))+
      theme(axis.title = element_text(size=6), axis.text.x = element_text(size = 5), axis.text.y = element_text(size = 5), panel.border = element_blank(), axis.line = element_line(colour = "black"))+
      theme_bw()+
      removeGridX() 
  plot_LR <- plot_LR + theme(axis.title = element_text(size=7), axis.text.x = element_text(size = 6), axis.text.y = element_text(size = 6), axis.line = element_line(colour = "black"))
  

pdf(file = "C:\\Users\\aisha\\OneDrive\\Documentos\\Mestrado Tinbergen\\Year 2\\Block 02\\Advanced Microeconometrics\\Computer assignment\\Mphil\\AdvMicroeconometrics\\Q2\\Fig02-Q2.pdf", width = 6, height = 3)
  grid.arrange(plot_AR, plot_t, plot_LM, plot_LR, ncol=2, nrow=2)
dev.off() 

```


### Item f
_Is there a difference between these confidence sets and if so can you explain why this difference occurs?_